# 1.3 特征工程

我们常说数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。那特征工程到底是什么呢？

特征工程是将原始数据转换为更能代表预测模型的潜在问题的特征的过程，主要包括特征选择和提取。接下来我们将分别讲解特征选择和特征提取。

## 1\) 特征选择

特征选择是指选择有意义的特征输入机器学习的算法和模型进行训练。通常来说，从两个方面考虑来选择特征：
* 特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。
* 特征与目标的相关性：选择目标相关性高的特征。

根据特征选择的形式又可以将特征选择方法分为3种：
* **Filter**：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。
* **Wrapper**：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。
* **Embedded**：集成法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。

### 1a\) Filter

| 方法| 含义 | python function |
| :--- | :--- | :--- |
| 方差选择法 | 使用方差选择法，先要计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。 | sklearn.feature_selection.VarianceThreshold |
| 相关系数法  |使用相关系数法，先要计算各个特征对目标值的相关系数以及相关系数的P值。|sklearn.feature_selection.SelectKBest& scipy.stats.pearsonr |
|卡方检验 |经典的卡方检验是检验定性自变量对定性因变量的相关性。  | sklearn.feature_selection.SelectKBest& scipy.stats.chi2 |
| 互信息法 |  经典的互信息也是评价定性自变量对定性因变量的相关性的 |sklearn.feature_selection.SelectKBest& scipy.stats.MINE |

### 1b\) Wrapper
| 方法| 含义 | python function |
| :--- | :--- | :--- |
| 递归特征消除法 | 递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。 | sklearn.feature_selection.RFE，参数estimator为基模型，参数n_features_to_select为选择的特征个数 |

### 1c\) Embedded
| 方法| 含义 |
| :--- | :--- |
| 基于惩罚项的特征选择法 | 使用带惩罚项的基模型，除了筛选出特征外，同时也进行了降维。 | sklearn.feature_selection.SelectFromModel(estimator)，要求Model需要带有conef_或者feature_importances属性 |
| 基于树模型的特征选择法  |树模型中GBDT也可用来作为基模型进行特征选择|

这两种方法都可以基于python函数sklearn.feature_selection.SelectFromModel(estimator,threshold=None, prefit=False, norm_order=1, max_features=None)。estimator为基模型，Model只需要带有conef_或者feature_importances属性。

## 2\) 特征提取

特征提取从最初的一组测量数据开始，构建旨在提供信息且非冗余的派生值（特征），通过X，创造新的X'，以促进后续的学习和泛化过程。

一个非常简单的例子，现在出一非常简答的二分类问题题，请你使用逻辑回归，设计一个身材分类器。输入数据X:身高和体重 ，标签为Y:身材等级（胖，不胖）。显然，不能单纯的根据体重来判断一个人胖不胖，姚明很重，他胖吗？显然不是。针对这个问题，一个非常经典的特征工程是，BMI指数，BMI=体重/(身高^2)。这样，通过BMI指数，就能非常显然地帮助我们，刻画一个人身材如何。甚至，你可以抛弃原始的体重和身高数据。

特征提取是一个降维过程，将原始变量的初始集合降维至更易于管理的组别（特征）进行处理，同时仍然准确、完整地描述原始数据集。

特征提取可以根据专家经验，也可以基于一些降维方法，例如：
> * 独立成分分析 Independent component analysis (ICA)
> * 核主成分分析 Kernel PCA
> * 主成分分析 Principal component analysis（PCA）
> * 非线性降维 Nonlinear dimensionality reduction
> * 自动编码器 Autoencoder




## 参考资料
[1. 特征工程到底是什么？](https://www.zhihu.com/question/29316149)

[2. 机器学习：特征工程、特征提取、特征选择与数据降维间的关系](https://blog.csdn.net/mechleechan/article/details/87153050)
