# 3.Machine Learning with Python

读者将会发现，机器学习的核心模型已经被**scikit-learn**等工具包非常好的模块化了，调用起来非常简单，仅需要几行代码，但是一个完整的、有效的机器学习工程项目却包括很多步骤，可以包括**数据导入，数据可视化理解，前处理，特征选择，模型训练，参数调整，模型预测，模型评估，后处理**等多个步骤，一个在真实世界中有效的模型可能需要工作者对数据的深入理解，以选择各个步骤合适的方法。

本章中我们进行实例讲解，根据BreastCance癌症数据集进行特征筛选和预测。通过本章教程，读者可以对机器学习的基本概念方法和具体流程有所了解，而且可以通过实践更好地掌握python相关工具包的使用，为后续的应用做好准备。

## 1\) Data

BreastCance癌症数据集可以在[这里](https://cloud.tsinghua.edu.cn/d/91cc41883ff2490d9829/)下载。

* 数据说明

> 1) 文件有11个列，第1个列为id号，第2-10列为特征，11列为标签（benign为良性、malignant为恶性）。
> 2) 数据集有458个良性（benign）样本和241个恶性（malignant）样本
> 3) 数据集有Cl.thickness，Cell.size，Cell.shape，Marg.adhesion，Epith.c.size，Bare.nuclei，Bl.cromatin，Normal.nucleoli，Mitoses等9个特征，每个特征取值为1-10。

部分数据如下：

| Id | Cl.thickness | Cell.size | Cell.shape | Marg.adhesion | Epith.c.size | Bare.nuclei | Bl.cromatin | Normal.nucleoli | Mitoses | Class |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 1000025 | 5 | 1 | 1 | 1 | 2 | 1 | 3 | 1 | 1 | benign |
| 1002945 | 5 | 4 | 4 | 5 | 7 | 10 | 3 | 2 | 1 | benign |
| 1015425 | 3 | 1 | 1 | 1 | 2 | 2 | 3 | 1 | 1 | benign |
| 1016277 | 6 | 8 | 8 | 1 | 3 | 4 | 3 | 7 | 1 | benign |
| 1017023 | 4 | 1 | 1 | 3 | 2 | 1 | 3 | 1 | 1 | benign |
| 1017122 | 8 | 10 | 10 | 8 | 7 | 10 | 9 | 7 | 1 | malignant |

Cl.thickness: Clump Thickness Cell.size: Uniformity of Cell Size Cell.shape: Uniformity of Cell Shape Marg.adhesion: Marginal Adhesion Epith.c.size: Single Epithelial Cell Size Bare.nuclei: Bare Nuclei Bl.cromatin: Bland Chromatin Normal.nucleoli: Normal Nucleoli Mitoses: Mitoses 如需了解更多关于BreastCancer数据集信息，可参考[mlbench](https://cran.r-project.org/web/packages/mlbench/index.html)的文档。

* 学习任务

> 1）从9个特征中找到预测效果最好的3个特征组合。
> 2）利用最佳的3个特征构建预测模型，并评估模型效果。


## 1\) Practice Guide


### 1a\) 导入需要的Python工具包

这里我们会导入一些后续操作需要的python工具包，它们的相关文档如下，请有兴趣的读者重点学习和了解[scikit-learn](http://scikit-learn.org/)工具包。

* [numpy](https://docs.scipy.org/doc/numpy/): arrays
* [pandas](https://pandas.pydata.org/): data IO, DataFrame
* [scikit-learn](http://scikit-learn.org/): machine learning
* [statsmodels](https://www.statsmodels.org/): statistical functions
* [matplotlib](https://matplotlib.org/): plotting
* [seaborn](https://matplotlib.org/): high-level plotting based on _matplotlib_


> tips: Anaconda并没有集成seaborn的最新版本，请使用pip更新seaborn：`pip install seaborn==0.9.0`

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import LinearSVC, SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import 
roc_curve,roc_auc_score,auc,precision_recall_curve,average_precision_score,accuracy_score
```

### 1b\) 载入数据并进行数据预处理

我们需要导入BreastCance癌症数据，然后进行空缺值填充、归一化处理。

* **数据导入：**

```python
data = pd.read_csv('BreastCancer.csv',sep=',')
feature = ['Cl.thickness', 'Cell.size', 'Cell.shape', 'Marg.adhesion',       'Epith.c.size', 'Bare.nuclei', 'Bl.cromatin', 'Normal.nucleoli',       'Mitoses']
X=data[feature]
Y=np.array(data['Class'].replace('benign',0).replace('malignant',1))
```

* **利用均值进行空缺值填充：**

```python
X_mean = X.mean(axis=0)
for i in range(len(X.T)):    
    X.iloc[:, i] = X.iloc[:, i].fillna(X_mean[i])
```

* **使用standard/z-score scaling 对数据做scaling:**

```python
X_sd = StandardScaler().fit_transform(X)
X = pd.DataFrame(X_sd)
X.columns=feature
```

### 1c\) 划分数据得到训练集和测试集

之前我们已经对数据进行了一些分析，并且做了一些基本的预处理，接下来我们需要对数据进行划分，得到训练集、验证集、测试集。

* 训练集：用于训练模型；
* 验证集：用于确定模型参数，这里我们用交叉验证的方法进行划分训练集和验证集用于特征选择；
* 测试集：不参与模型训练过程，仅用于评价模型效果。

因为模型总是会在某种程度上过拟合训练数据，因此在训练数据上评估模型是有偏的，模型在训练集上的表现总会比测试集上好一些。

因为模型总是可以学到数据中隐藏的模式和分布，如果样本间彼此的差异比较大，过拟合问题就会得到一定程度的减轻。而如果数据的量比较大，模型在训练集和测试集上的表现差异就会减小。

* **划分训练集和测试集** 

这里我们使用[train\_test\_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) 方法来随机的将80%的样本设置为训练样本， 将其余20%设置为测试样本。

```python
random_state = np.random.RandomState(1289237)
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)
X_train.index = range(len(X_train))
X_test.index = range(len(X_test))
print('number of training samples: {}, test samples: {}'.format(X_train.shape[0], X_test.shape[0]))
```

```text
number of training samples: 559, test samples: 140
```

* **划分训练集和验证集** 

验证集（validation set），是将训练集再随机划分为训练集和验证集，进行多折交叉验证（[cross validation](https://www.zhihu.com/question/39259296)）。

我们利用5-fold cross validation计算得到验证集的平均AUC，然后评估不同特征组合。

### 1d\) 特征选择

本节我们利用封装式进行特征选择。每个特征组合，我们利用5-fold cross validation计算得到验证集的平均AUC，进行评估。

在训练过程中，我们自定义函数clf_select，包括LR，RF，DT，SVM等模型。我们根据[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)进行超参数选择。

* **模型函数(clf_select)**

```python
def clf_select(name):
    if name =='DT':
        clf = DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, criterion='gini')
    elif name =='DT_cv':
        tree_para = {'max_depth': [3,5,7,9]}
        clf = GridSearchCV(DecisionTreeClassifier(), tree_para, cv=5)
    elif name == 'SVM':
        clf = SVC(kernel='rbf', probability=True, C=1)
    elif name == 'SVM_cv':
        tree_para = { 'C':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]}
        clf = GridSearchCV(SVC(kernel= 'rbf',probability=True), tree_para, cv=5)
    elif name == 'RF':
        clf = RandomForestClassifier(n_estimators=50, max_depth=5)
    elif name == 'RF_cv':
        tree_para = {'n_estimators': [25, 50, 75],'max_depth': [3, 4, 5]}
        clf = GridSearchCV(RandomForestClassifier(), tree_para, cv=5)
    elif name == 'LR_cv':
        tree_para = {'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]}
        clf = GridSearchCV(LogisticRegression(penalty='l2',solver='liblinear'), tree_para, cv=5)
    return clf
```

* **计算可能的特征组合**

我们枚举出所有的3个特征的组合，这里特征组合包含的特征个数也是一个超参数，我们这里以3个特征的组合为例。

```python
from itertools import combinations
feature_list=[]
for i in combinations(feature, 3):
    feature_list.append(list(i))
```

* **对每个特征组合进行交叉验证**

```python
# 交叉验证的平均AUC
result_train = pd.DataFrame(columns={'feature', 'AUC_mean'})
result_val = pd.DataFrame(columns={'feature', 'AUC_mean'})

for j in range(len(feature_list)):
    print(j)
    # 交叉验证划分
    skf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True)
    # 交叉验证中每一折结果
    result_train_= pd.DataFrame(columns={'num', 'AUC'})
    result_val_ = pd.DataFrame(columns={'num', 'AUC'})
    n=0
    for train, test in skf.split(list(X_train.index), y_train):
        # 训练集、验证集
        X_train_ = X_train.loc[train,feature_list[j]]
        X_val = X_train.loc[test,feature_list[j]]
        y_train_ = y_train[train]
        y_val = y_train[test]
        
        # 模型训练，我们自定义clf_select函数
        clf = clf_select('DT_cv')
        clf.fit(X_train_, y_train_)
        
        # 模型预测结果
        pred_proba_train = clf.predict_proba(X_train_)
        fpr_train, tpr_train, thresholds = roc_curve(y_train_, pred_proba_train[:, 1])
        roc_auc_train = auc(fpr_train, tpr_train)
        pred_proba_val = clf.predict_proba(X_val)
        fpr_val, tpr_val, thresholds = roc_curve(y_val, pred_proba_val[:, 1])
        roc_auc_val = auc(fpr_val, tpr_val)

        result_train_.loc[n,'num']=n
        result_train_.loc[n,'AUC'] = roc_auc_train
        result_val_.loc[n,'num']=n
        result_val_.loc[n,'AUC'] = roc_auc_val
        n=n+1
    
    # 模型验证集平均AUC计算
    result_train.loc[j,'feature']=','.join(feature_list[j])
    result_train.loc[j, 'AUC_mean'] = result_train_['AUC'].mean()
    result_val.loc[j,'feature']=','.join(feature_list[j])
    result_val.loc[j, 'AUC_mean'] = result_val_['AUC'].mean()
```

* **最佳特征组合 (根据验证集的平均AUC)**

```python
best_feature=result_val.loc[result_val.sort_values('AUC_mean',ascending=False).index[0],'feature'].split(',')
```
结果为：

```text
'Cl.thickness', 'Cell.size', 'Bare.nuclei'
```

### 1e\) 模型评价

根据上面的过程我们找到了最佳特征组合，为了进行模型评价我们需要进行训练集和测试集上测试。
> * 训练集上5折交叉验证
> * 在整个训练集\(training set\)上进行模型训练，测试集测试。



### 1f）训练集上的交叉验证

我们首先在**训练集**上做**K折（k-folds）交叉验证**，在训练集上划分出一部分用于**训练**，另一部分用于**验证**，可以帮助我们挑选比较不同的模型，以及挑选模型中的超参数。

* **交叉验证的ROC曲线**

下面的代码展示_KFold_是如何划分数据集的，图片中每一行为一个轮次，每一行中黑色的box为该轮次的测试集

```python
# 交叉验证
skf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)
best_train_ = pd.DataFrame(columns={'num', 'fpr','tpr'})
best_val_ = pd.DataFrame(columns={'num', 'fpr','tpr'})
n = 0
for train, test in skf.split(list(X_train.index), y_train):
    result_train_= pd.DataFrame(columns={'num', 'fpr','tpr'})
    result_val_ = pd.DataFrame(columns={'num', 'fpr','tpr'})
    X_train_ = X_train.loc[train, best_feature]
    X_val = X_train.loc[test, best_feature]
    y_train_ = y_train[train]
    y_val = y_train[test]
    # 模型训练
    clf = clf_select('DT_cv')
    clf.fit(X_train_, y_train_)
    # 模型预测
    pred_proba_train = clf.predict_proba(X_train_)
    fpr_train, tpr_train, thresholds = roc_curve(y_train_, pred_proba_train[:, 1])
    roc_auc_train = auc(fpr_train, tpr_train)
    pred_proba_val = clf.predict_proba(X_val)
    fpr_val, tpr_val, thresholds = roc_curve(y_val, pred_proba_val[:, 1])
    roc_auc_val = auc(fpr_val, tpr_val)
    
    # 汇总5 fold cross validation的结果
    result_train_['fpr']=fpr_train
    result_train_['tpr'] = tpr_train
    result_train_['num']=n
    best_train_ = pd.concat([best_train_,result_train_])
    result_val_['fpr']=fpr_val
    result_val_['tpr'] = tpr_val
    result_val_['num']=n
    best_val_ = pd.concat([best_val_, result_val_])
    n = n + 1

# ROC曲线
plt.figure(figsize=(4,4))
sns.lineplot(x='fpr', y='tpr',ci="sd", data=best_train_,estimator="mean",label='Train set')
sns.lineplot(x='fpr', y='tpr',ci="sd", data=best_val_,estimator="mean",label='Validation set')
plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random Chance')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.title('ROC curve of cv in train data')
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.legend(loc='best',fontsize='small')
plt.tight_layout()
plt.show()
plt.close()

```

![](../../png/4.3.ml_train_roc.png)



### 1g\) 在测试集\(test set\)上预测和评估整个训练集\(traning set\)得到的模型

* **整个训练集训练**

```python
clf = clf_select('DT_cv')
clf.fit(X_train, y_train)
```

* **测试集上预测ROC**

```python
y_predict=clf.predict(X_test)
proba=clf.predict_proba(X_test).T[1]
fpr, tpr, thresholds = roc_curve(y_test, proba)
roc_auc = auc(fpr, tpr)

# 画ROC曲线
plt.figure(figsize=(4,4))
plt.plot(fpr, tpr, '-', color='b', label='Test AUC of {:.4f}'.format(roc_auc), lw=2)
plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random Chance')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.title('ROC curve of test data')
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.legend(loc='best',fontsize='small')
plt.tight_layout()
plt.show()
plt.close()
```

![](../../png/4.3.ml_test_roc.png)

可以看到AUROC接近于1，可以认为模型的分类效果很好。

## 2\) Homework

按照教程中的流程，对我们给定的qPCR数据进行特征筛选和预测模型构建，给出最佳的模型组合和训练集、验证集、测试集的ROC曲线。


 * 数据：qPCR数据（可从利用提供[文件](https://cloud.tsinghua.edu.cn/d/91cc41883ff2490d9829/)）。数据集包括11个特征，两种类别（正常NC和病人HCC）。
> * 数据特征：第1列为sample id，第2-12列为特征（包含11个基因），第13列为样本标签
> * 数据标签处理：正样本为NC，负样本为HCC
> * 数据预处理：1）去除含有空缺值的样本 2）对数据进行归一化
> * 数据集划分：训练集和测试集划分参考教程中的80%/20%划分方式，程序运行最开头加上random\_state = np.random.RandomState\(1289237\)保证划分一致
> * 分类器模型：LR,SVM,DT,RF
> * 编程工具：R/python
> * 作业要求：上传word/pdf文档附件，记录处理过程所用代码，并绘制ROC曲线。

